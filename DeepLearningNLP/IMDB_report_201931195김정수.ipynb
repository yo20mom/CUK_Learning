{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_report_김정수.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNU43QRKgSyKvbpbXRSYalL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yo20mom/CUK_Learning/blob/master/DeepLearningNLP/IMDB_report_201931195%EA%B9%80%EC%A0%95%EC%88%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D84I5rvaZ2JU"
      },
      "source": [
        "# 사용할 패키지 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQOkvAoxY5mh"
      },
      "source": [
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense, BatchNormalization, SpatialDropout1D, Activation\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fdSOHkXZvWh"
      },
      "source": [
        "# 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbDu3aSGip_5"
      },
      "source": [
        "# loss, acc 시각화 함수\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUQXHABZY0CJ"
      },
      "source": [
        "vocab_size = 10000  # final field\n",
        "(X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words = vocab_size)\n",
        "print(X_train.shape)\n",
        "#0th sentence\n",
        "\n",
        "print(len(X_train[0]))\n",
        "\n",
        "#1th sentence\n",
        "print(len(X_train[1]))\n",
        "\n",
        "max_len = 200\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)\n",
        "\n",
        "print('X_train의 크기(shape) :',X_train.shape)\n",
        "print('X_test의 크기(shape) :',X_test.shape)\n",
        "print(y_train[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xNANEU4a3hB"
      },
      "source": [
        "X_train[0]# 맨 마지막 숫자가 32인 경우, 더 긴 문장을 자른 형태"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqHmRh_GcJl0"
      },
      "source": [
        "X_train[1]# 문장의 수가 모자란 경우 앞에서 부터 0으로 채운다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8veuvmqcmtU"
      },
      "source": [
        "# Model Build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iRDUI3Nctg0"
      },
      "source": [
        "inputs = layers.Input(shape=(None,), dtype='int64')\n",
        "\n",
        "embedded_sequences = layers.Embedding(input_dim = vocab_size, output_dim = 256)(inputs)\n",
        "x = layers.Dropout(0.3)(embedded_sequences)\n",
        "x = layers.Conv1D(256, 3, padding='valid')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(activation='relu')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "\n",
        "x = layers.Dense(128)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(activation='relu')(x)\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(1e-3),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybSxnS5tgwKL"
      },
      "source": [
        "# 최고 학습 모델 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jOpVoJTg1OV"
      },
      "source": [
        "es = EarlyStopping(monitor = 'val_loss',\n",
        "                   mode = 'min',\n",
        "                   verbose = 1,\n",
        "                   patience = 3)\n",
        "mc = ModelCheckpoint('best_model.h5', \n",
        "                     monitor = 'val_acc', \n",
        "                     mode = 'max', \n",
        "                     verbose = 1, \n",
        "                     save_best_only = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5Yncx9mhzta"
      },
      "source": [
        "# 모델학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLKFkbiehOgT"
      },
      "source": [
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs = 3,\n",
        "                    validation_data = (X_test, y_test),\n",
        "                    callbacks=[es, mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYjKmh5XEi2l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWkFakRbiRXx"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11ah8H4bYqVx"
      },
      "source": [
        "plot_graphs(history, 'acc')\n",
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf0Bqa7Tnl_Z"
      },
      "source": [
        "\n",
        "# hyper parameter 튜닝하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q_6wRe4njoj"
      },
      "source": [
        "# del model  # 위에서 학습한 모델은 삭제\n",
        "\n",
        "history_arr = []  # history 저장\n",
        "eval_arr = []  # evaluate 값 저장\n",
        "\n",
        "def run_model(dropout_rate, learning_rate):\n",
        "  inputs = layers.Input(shape=(None,), dtype='int64')\n",
        "\n",
        "  embedded_sequences = layers.Embedding(input_dim=vocab_size,\n",
        "                                        output_dim=256)(inputs)\n",
        "\n",
        "  x = layers.Dropout(dropout_rate)(embedded_sequences)\n",
        "  x = layers.Conv1D(256, 3, padding='valid')(x)\n",
        "  x = layers.Activation(activation='relu')(x)\n",
        "  x = layers.GlobalMaxPool1D()(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "\n",
        "  x = layers.Dropout(dropout_rate)(x)\n",
        "  x = layers.Dense(128)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(activation='relu')(x)\n",
        "\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "\n",
        "  outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = models.Model(inputs, outputs)\n",
        "\n",
        "  best_model_name = 'best_model_{}_{}.h5'.format(str(learning_rate)[2:], round(dropout_rate * 10))\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', \n",
        "                   mode='min', \n",
        "                   verbose=2, \n",
        "                   patience=2)\n",
        "\n",
        "  mc = ModelCheckpoint(best_model_name, \n",
        "                      monitor='val_acc', \n",
        "                      mode='max', \n",
        "                      verbose=2, \n",
        "                      save_best_only=True)\n",
        "\n",
        "  model.compile(optimizer=optimizers.Adam(learning_rate),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  \n",
        "  history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=2,\n",
        "                    verbose=2,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[es, mc])\n",
        "  \n",
        "  loaded_model = load_model(best_model_name)\n",
        "  print(\"\\n [%s], 테스트 정확도: %.4f\" % (best_model_name, loaded_model.evaluate(X_test, y_test)[1]))\n",
        "  eval_arr.append(loaded_model.evaluate(X_test, y_test)[1])\n",
        "  history_arr.append(history)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdNwi4Wbt7bW"
      },
      "source": [
        "import numpy as np\n",
        "dropout_arr = np.arange(0.1, 1.0, 0.1)  # 최적화 dropout 찾기\n",
        "\n",
        "for x in [1e-2, 1e-3, 1e-4]:\n",
        "  print(\"=\" * 33)\n",
        "  print(\" start learning_rate :: {}\".format(x))\n",
        "  for j in dropout_arr:\n",
        "    print(\"--\" * 20)\n",
        "    print(\" dropout rate : {}\".format(j))\n",
        "    print(\"--\" * 20)\n",
        "    rate = np.round(j, 1)\n",
        "    run_model(rate, x)\n",
        "  print(\"=\" * 33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEqnXEPRJiFL"
      },
      "source": [
        "# accuracy 및 loss 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24CzBdoxub-p"
      },
      "source": [
        "for i, x in enumerate(history_arr):\n",
        "  print(\"==\" * 30)\n",
        "  print(\"history idx : %d\" % i)\n",
        "  plot_graphs(x, 'acc')\n",
        "  plot_graphs(x, 'loss')\n",
        "  print(\"==\" * 30)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}