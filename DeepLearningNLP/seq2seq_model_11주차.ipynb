{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_model_11주차.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOGq6KArZo2Y08C0BvTbl+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yo20mom/CUK_Learning/blob/master/DeepLearningNLP/seq2seq_model_11%EC%A3%BC%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCmvzrJyOW_k"
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.backend as K\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLAq16HqPV7i"
      },
      "source": [
        "\n",
        "Dataset 준비하기\n",
        "실제 실무에서와 같이 데이터 전처리 하는데에 시간이 꽤나 오래 걸립니다. 그러나 모델 작성은 그리 어렵지 않으니, 실습에 너무 큰 부담을 가지 마시길 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOlRB2RuPUy0"
      },
      "source": [
        "!!curl -O http://www.manythings.org/anki/fra-eng.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXnhNvzEPbHN"
      },
      "source": [
        "!unzip fra-eng.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_XFp6ySPgpO"
      },
      "source": [
        "f = open('fra.txt','r')\n",
        "lines = f.readlines()\n",
        "print(lines[0])\n",
        "print(lines[4])\n",
        "\n",
        "eng_sents, fra_sents = [], []\n",
        "\n",
        "# 한 문장을 영어와 불어를 분리해 따로 저장\n",
        "\n",
        "for line in lines:\n",
        "    eng, fra, _ = line.split('\\t')\n",
        "    eng_sents.append(eng)\n",
        "    fra_sents.append(fra)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUCxBEakPkYY"
      },
      "source": [
        "eng_sents[0], fra_sents[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1ZGbDIsPmza"
      },
      "source": [
        "print('데이터의 총 개 수', len(lines))\n",
        "eng_sent_lengths = [len(eng_sent) for eng_sent in eng_sents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izLUfdZlPopJ"
      },
      "source": [
        "#EDA eng\n",
        "\n",
        "eng_sents_series = pd.Series(eng_sents)\n",
        "eng_sents_series.apply(len).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8snytE9oPsEK"
      },
      "source": [
        "#EDA fra\n",
        "\n",
        "fra_sents_series = pd.Series(fra_sents)\n",
        "fra_sents_series.apply(len).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3II0yP-PxST"
      },
      "source": [
        "for ind, eng_sent in enumerate(eng_sents):\n",
        "    eng_sents[ind] = eng_sent + ' '\n",
        "\n",
        "for ind, fra_sent in enumerate(fra_sents):\n",
        "    fra_sents[ind] = fra_sent + ' '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q5-_cGmP026"
      },
      "source": [
        "# change char to number\n",
        "\n",
        "eng_chars = set(\"\".join(eng_sents))\n",
        "print('# English chars : ',len(eng_chars))\n",
        "\n",
        "# generate English char level dictionary\n",
        "eng_char_dict = {}\n",
        "for ind, eng_char in enumerate(eng_chars):\n",
        "    eng_char_dict[eng_char] = ind\n",
        "\n",
        "\n",
        "fra_chars = set(\"\".join(fra_sents))\n",
        "print('# English chars : ',len(fra_chars))\n",
        "\n",
        "# generate Franch char level dictionary\n",
        "fra_char_dict = {}\n",
        "for ind, fra_char in enumerate(fra_chars):\n",
        "    fra_char_dict[fra_char] = ind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fthqKskTP2zm"
      },
      "source": [
        "#change all english to number\n",
        "\n",
        "eng_vectors = []\n",
        "\n",
        "for eng_sent in eng_sents:\n",
        "    eng_vectors.append([eng_char_dict[eng_char] for eng_char in eng_sent])\n",
        "\n",
        "#change all franch to number\n",
        "\n",
        "fra_vectors = []\n",
        "\n",
        "for fra_sent in fra_sents:\n",
        "    fra_vectors.append([fra_char_dict[fra_char] for fra_char in fra_sent])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpC5_xdMP6lZ"
      },
      "source": [
        "print(eng_sents[0], eng_vectors[0])\n",
        "eng_char_dict['G'], eng_char_dict['o'], eng_char_dict['o'], eng_char_dict[' ']\n",
        "\n",
        "print(fra_sents[0], fra_vectors[0])\n",
        "fra_char_dict['V'], fra_char_dict['a'], fra_char_dict[' '], fra_char_dict['!']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjXa6U-KP8S6"
      },
      "source": [
        "#change english vector to onehot vector\n",
        "eng_input_onehots = [to_categorical(eng_vector, len(eng_chars)) for eng_vector in eng_vectors]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JttGAsxsQAtM"
      },
      "source": [
        "fra_input_vectors = [fra_vector[:-1] for fra_vector in fra_vectors]\n",
        "fra_output_vectors = [fra_vector[1:] for fra_vector in fra_vectors]\n",
        "\n",
        "#change franch vector to onehot vector\n",
        "fra_input_onehots = [to_categorical(fra_vector, len(fra_chars)) \n",
        "                    for fra_vector in fra_input_vectors]\n",
        "\n",
        "fra_output_onehots = [to_categorical(fra_vector, len(fra_chars))\n",
        "                       for fra_vector in fra_output_vectors]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yVJP8WIQCih"
      },
      "source": [
        "fra_vectors[0], fra_input_vectors[0], fra_output_vectors[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60NeshSEQEOk"
      },
      "source": [
        "train_xs = [eng_input_onehots, fra_input_onehots]\n",
        "train_ys = fra_output_onehots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgjT-tE-QIDd"
      },
      "source": [
        "\n",
        "Build Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72rqPTKaQF5I"
      },
      "source": [
        "K.clear_session()\n",
        "#encoder model\n",
        "encoder_inputs = Input(shape=(None,len(eng_chars)))\n",
        "latent_dim = 256\n",
        "encoder = LSTM(latent_dim,return_state=True)\n",
        "encoder_ouputs, encoder_h, encoder_c = encoder(encoder_inputs)\n",
        "encoder_ouputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X2__hQHQVnb"
      },
      "source": [
        "Build Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r9EUg04QOEx"
      },
      "source": [
        "decoder_inputs = Input(shape=(None, len(fra_chars)))\n",
        "\n",
        "latent_dim = 256\n",
        "decoder = LSTM(latent_dim,return_state=True, return_sequences=True)\n",
        "decoder_ouputs, _, _ = decoder(decoder_inputs, initial_state=[encoder_h, encoder_c])\n",
        "decoder_ouputs = Dense(units=len(fra_chars), activation='softmax')(decoder_ouputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79qpQ_hbQeM1"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JbfcICaQcUG"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_ouputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Baag4z9QieX"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIxalD4uQkZ_"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_acc = []\n",
        "    epoch_loss = []\n",
        "    for ind in tqdm(range(len(train_xs[0]))):\n",
        "        xs_0 = np.array(train_xs[0][ind: ind+1])\n",
        "        xs_1 = np.array(train_xs[1][ind: ind+1])\n",
        "        ys = np.array(train_ys[ind: ind+1])\n",
        "\n",
        "        hist = model.fit([xs_0,xs_1],ys, batch_size=1, epochs=1, verbose = False)\n",
        "        epoch_acc.append(hist.history['accuracy'])\n",
        "        epoch_loss.append(hist.history['loss'])\n",
        "    print('acc', np.mean(epoch_acc))\n",
        "    print('loss', np.mean(epoch_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X7kUPHvQorW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}