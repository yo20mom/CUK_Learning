{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KERAS_REPORT_CNN_마사짱.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMi9DKF7M2+c3HTruXUeYZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yo20mom/CUK_Learning/blob/master/KerasDeepLearning/KERAS_REPORT_CNN_%EB%A7%88%EC%82%AC%EC%A7%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bRErQIN8_Oy"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, utils, callbacks, datasets, layers, applications, optimizers\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Activation, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras import backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsDwu7aH9z3g"
      },
      "source": [
        "NUM_EPOCHS = 33\n",
        "INIT_LEARNING_RATE= 1e-2\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No4hxMSpBZSe"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeqvZHJKBtW8"
      },
      "source": [
        "def my_model(filters=[32, 64], kernel_size=(3, 3), pool_size=(2, 2), act='relu'):\n",
        "  width, height, depth, classes = 28, 28, 1, 10\n",
        "  \n",
        "  model = Sequential()\n",
        "  input_shape = (height, width, depth)\n",
        "  chan_dim = -1\n",
        "\n",
        "  for i, x in enumerate(filters):\n",
        "    if i == 0:\n",
        "      model.add(Conv2D(filters=x, \n",
        "                       kernel_size=kernel_size, \n",
        "                       padding='same',\n",
        "                       input_shape=input_shape))\n",
        "    else:\n",
        "      model.add(Conv2D(filters=x, kernel_size=kernel_size, padding='same'))\n",
        "\n",
        "    model.add(BatchNormalization(axis=chan_dim))\n",
        "    model.add(Activation(act))\n",
        "    model.add(Conv2D(filters=x, kernel_size=kernel_size, padding='same'))\n",
        "    model.add(BatchNormalization(axis=chan_dim))\n",
        "    model.add(Activation(act))\n",
        "    model.add(MaxPooling2D(pool_size=pool_size))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  \n",
        "  model.add(Dense(512))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(act))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(512))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(act))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X05wNovEJdfQ"
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ed-k1B2Jo-h"
      },
      "source": [
        "x_train =x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "x_test = x_test.reshape(x_test.shape[0],28 ,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WBB0A8eJz8D"
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRSZOn1MKjCv"
      },
      "source": [
        "#값 정규화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT7zx8g_KY6g"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM03i60CK0OB"
      },
      "source": [
        "x_train[83][11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PgCiDA9Lq0G"
      },
      "source": [
        "label_names = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
        "def get_answer(num):\n",
        "    return label_names[num]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BE5_yyFK6Pl"
      },
      "source": [
        "row = 77\n",
        "#print(get_answer(y_train[row]))\n",
        "plt.imshow(x_train[row].reshape(28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d73PGbg4T5vu"
      },
      "source": [
        "# 원핫 인코딩으로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieu7so0yUA43"
      },
      "source": [
        "classes = len(np.unique(y_train))\n",
        "y_train = to_categorical(y_train, num_classes=classes)\n",
        "y_test = to_categorical(y_test, num_classes=classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYGf1-aMNR0q"
      },
      "source": [
        "# 모델 저장 기준이 되는 콜백 import\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSStpywKOPlT"
      },
      "source": [
        "# 체크할 포인트\n",
        "check_point = ModelCheckpoint('best_model.h5', \n",
        "                              monitor='val_accuracy',\n",
        "                              verbose=1,\n",
        "                              save_best_only=True)\n",
        "\n",
        "# 이른 스탑을 위한 클래스\n",
        "early_stopping = EarlyStopping(monitor='val_accruacy',\n",
        "                               min_delta=0,\n",
        "                               patience=7,\n",
        "                               verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIJ0BnbiNzMA"
      },
      "source": [
        "# 모델 컴파일 및 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiUrlUU5QgZK"
      },
      "source": [
        "bat_size = 128\n",
        "epochs = 33\n",
        "for lr, bs, ep in zip([0.001], [bat_size] * 1, [epochs] * 1):\n",
        "  optimizer = Adam(learning_rate=lr, \n",
        "                  decay=lr / ep, \n",
        "                  beta_1=0.9,\n",
        "                  beta_2=0.999)\n",
        "\n",
        "\n",
        "  model = my_model()\n",
        "\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  history = model.fit(x_train,\n",
        "                      y_train,\n",
        "                      batch_size=bs,\n",
        "                      validation_split=0.3,\n",
        "                      validation_data=(x_test, y_test),\n",
        "                      epochs=ep,\n",
        "                      verbose=2,\n",
        "                      callbacks=[check_point, early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FZStfNbjt89"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "\n",
        "prob_pred = loaded_model.predict(x_test)\n",
        "pred = loaded_model.evaluate(x_test, y_test)\n",
        "print(pred)\n",
        "\n",
        "prob_label = prob_pred.argmax(axis=-1)\n",
        "\n",
        "np.savetxt('y_pred.csv', prob_label, fmt='%d')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}